{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow, Keras and MNIST\n",
    "#### David Gallagher\n",
    "\n",
    "### Brief Introduction.\n",
    "\n",
    "This notebook documents and outlines research into building a Neural Network (NN) using Tensorflow with Keras and MNIST as training data. The NN will be used to predict numbers given to it from a [web client](https://github.com/d-gallagher/ET_Jupyter) wherein users will draw digits on a canvas.\n",
    "\n",
    "#### Research into [Tensorflow](https://www.tensorflow.org/), and [Keras](https://keras.io/).\n",
    "##### Tensorflow\n",
    "An open source library for numerical computation and large-scale machine learning developed by the [Google Brain team](https://ai.google/research/teams/brain/). Tensorflow is a framework which combines a number of useful machine learning and deep learning models and algorithms. It uses [Python](https://www.python.org/) for building applications and executes those applications in C++ making it highly performant. Tensorflow is available for deep neural network applications based in [Image Recognition](https://www.tensorflow.org/tutorials/images/classification), [Language Processing](https://www.tensorflow.org/tutorials/text/word_embeddings) and [Handwritten digit recognition](https://www.tensorflow.org/js/tutorials/training/handwritten_digit_cnn) to name a few.\n",
    "\n",
    "##### Keras\n",
    "Keras is one of the leading high-level neural networks APIs, written in [Python](https://www.python.org/) and runs on top of the aforementioned [Tensorflow](https://www.tensorflow.org/), [Theano](http://deeplearning.net/software/theano/) and other deep learning frameworks. Originally developed by Fran√ßois Chollet, an engineer at Google, to be modular, minimalist, extensible and Python specific. It is set to be fully adopted by the upcoming [Tensorflow 2.0](https://www.tensorflow.org/guide/effective_tf2).\n",
    "\n",
    "#### [Brief Summary of MNIST](http://yann.lecun.com/exdb/mnist/)\n",
    "MNIST is a database of handwritten digits which can be used to train a NN for digit recognition. It comprises a training set of 60,000 examples, and a test set of 10,000 examples of digits which have been size-normalized and centered in a fixed-size image of 28 * 28 pixels. MNIST is a subset of the [NIST](https://www.nist.gov/itl/products-and-services/emnist-dataset) dataset with each digit processed to fit in a 20 * 20 pixel box preserving their original aspect ratio, then centered by computing their centre of mass, and placed on a 28 * 28 field.\n",
    "\n",
    "Following a basic tutorial from [Moodle](https://nbviewer.jupyter.org/github/ianmcloughlin/jupyter-teaching-notebooks/blob/master/mnist.ipynb) I further adapted the NN from the following sources: \n",
    "* [Deep Learning with Python, TensorFlow, and Keras](https://www.youtube.com/watch?v=wQ8BIBpya2k)\n",
    "* [Deep Learning Quick Start: MNIST in Keras](https://www.ics.uci.edu/~mohamadt/keras_mnist.html)\n",
    "* [Deeplizard Keras and Flask](https://www.youtube.com/playlist?list=PLv3j2_RROTdFyX3tYbEizaVXYHOdpgmQF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape (60000, 28, 28)\n",
      "Original Y shape (60000,)\n",
      "Training X matrix shape (60000, 784)\n",
      "Testing X matrix shape (10000, 784)\n",
      "Y_train[0]  5\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2316 - acc: 0.9322\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.0972 - acc: 0.9701\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0680 - acc: 0.9789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x202d8152c18>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the tensorflow framework (contains Keras)- rename to 'tf' for minimal typing later\n",
    "import tensorflow as tf\n",
    "# %matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Get the mnist dataset from keras\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# Unpack training and test datasets\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "# Printing the shape of the x training sets shows us there are 60000 items of size 28*28 rows*cols\n",
    "print(\"Original X shape\", X_train.shape)\n",
    "# The y training set consists of 60000 labels for the x image samples\n",
    "print(\"Original Y shape\", Y_train.shape)\n",
    "\n",
    "\"\"\"\n",
    "We need to reshape the data prior to training. Our sample are 2 dimensional.\n",
    "In order to process the images in the NN we need to add a depth dimension.\n",
    "This is achieved by reshaping the images using the .reshape() function.\n",
    "Since our Images are in greyscale as opposed to RGB we reshape the array to 784 (28*28*1).\n",
    "RGB would be (28*28*3) for example..\n",
    "Following that we are converting our samples from uint8 to floats and scaling(normalizing) to between 0-1.\n",
    "\"\"\"\n",
    "\n",
    "# Reshape data.\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test  = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32') \n",
    "X_test  = X_test.astype('float32')\n",
    "X_train /= 255 # Original data is uint8 (0-255). Scale it to range [0,1].\n",
    "X_test  /= 255\n",
    "\n",
    "# Quick print to view and confirm the newly applied shapes\n",
    "print(\"Training X matrix shape\", X_train.shape)\n",
    "print(\"Testing X matrix shape\", X_test.shape)\n",
    "\n",
    "# Sequential model (add layer by layer), less complex than a functional model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Twon layers of 128 neurons, relu (rectified linear) as activation function\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu,input_shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "\n",
    "# Output Layer - 10 neurons, using Softmax for probability distribution\n",
    "model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))\n",
    "\n",
    "# Training params for the model: using 'adam' optimizer, loss for degree of error, return accuracy metrics\n",
    "# sparse_categorical_crossentropy with 10 classes gives us a final output between 0-9, which is exactly what we need for MNIST\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with the given inputs. 'epochs' - how many times we run the training. (Any more than 3 epochs offered diminishing returns.)\n",
    "model.fit(X_train, Y_train, epochs=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have built our NN model!.\n",
    "Time to evaluate the training and determine accuracy against the validation samples.\n",
    "#### [Whats the difference between the training and testing sets?](https://stackoverflow.com/questions/2976452/whats-is-the-difference-between-train-validation-and-test-set-in-neural-netwo)\n",
    "See 'Whats the difference' above for a more detailed explanation about training, testing and validation.\n",
    "The accuracy is pretty good for a basic NN. Convolutional NN's can offer further improvements on accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0742 - acc: 0.9774\n",
      "0.0741552268156549 0.9774\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss and accuracy validations\n",
    "val_loss, val_acc = model.evaluate(X_test, Y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for use in our FLask Application.\n",
    "model.save('numberPredictor.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test the saved model to confirm it's working as expected and determine accuracy against selected sample images. We will load our saved model, using numpy and pyplot to help us confirm our test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Load the saved Model\n",
    "working_model = tf.keras.models.load_model('numberPredictor.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.2619250e-07 4.6378750e-06 2.5454779e-05 ... 9.9989843e-01\n",
      "  1.3449841e-06 3.8400616e-05]\n",
      " [6.2954015e-08 1.5632308e-05 9.9998176e-01 ... 1.0175439e-08\n",
      "  5.1707680e-08 2.8914429e-10]\n",
      " [1.2114575e-07 9.9903524e-01 1.1187329e-04 ... 1.8841791e-04\n",
      "  2.7816423e-04 1.6330021e-06]\n",
      " ...\n",
      " [2.3647076e-10 1.3161342e-08 1.0177782e-09 ... 2.6402788e-05\n",
      "  9.8740918e-07 4.0897357e-06]\n",
      " [1.2538927e-06 1.7515413e-07 7.5747195e-09 ... 3.9677229e-04\n",
      "  4.6606679e-04 6.5488152e-08]\n",
      " [2.4133145e-10 1.1809413e-10 2.4370175e-09 ... 1.6442181e-11\n",
      "  2.9822975e-10 7.9000410e-11]]\n"
     ]
    }
   ],
   "source": [
    "# Predictions is the loaded model predicting what number it has been given from the test set\n",
    "predictions = working_model.predict([X_test])\n",
    "# This prints the output for the entire dataset, we will narrow it down by selecting individual sample images below.\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Using numpy to display the predicted number in the list.\n",
    "import numpy as np\n",
    "print(np.argmax(predictions[90]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Reshape (784,)\n",
      "After Reshape (784,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using matplotlib to display the predicted number for comparison\n",
    "print(\"Before Reshape\", X_test[90].shape)\n",
    "plt.imshow(X_test[90].reshape(28, 28), cmap=\"gray\")\n",
    "print(\"After Reshape\",X_test[90].shape)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
